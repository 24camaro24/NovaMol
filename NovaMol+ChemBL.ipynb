{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulwasaeee/NovaMol/blob/main/NovaMol%2BChemBL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Project: NovaMol 2.0 - A Drug Discovery Engine with ChEMBL\n",
        "#\n",
        "# Objective:\n",
        "# This pipeline specializes in pharmaceutical discovery. It uses the ChEMBL\n",
        "# database to train a multi-task GNN to predict drug-like properties and\n",
        "# bioactivity. The goal is to generate novel molecules and evaluate their\n",
        "# potential as high-quality drug candidates.\n",
        "# =============================================================================\n",
        "\n",
        "# --- Step 1: Setup and Installations ---\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Installs required packages, including the ChEMBL client.\"\"\"\n",
        "    print(\"--- Checking and installing dependencies ---\")\n",
        "    standard_packages = [\n",
        "        \"rdkit\", \"pandas\", \"scikit-learn\", \"tqdm\", \"torch\",\n",
        "        \"torchvision\", \"torchaudio\", \"selfies\", \"chembl_webresource_client\"\n",
        "    ]\n",
        "    for package in standard_packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"ERROR: Failed to install {package}. Please try installing it manually.\")\n",
        "            sys.exit(1)\n",
        "    try:\n",
        "        import torch\n",
        "        TORCH_VERSION = torch.__version__.split('+')[0]\n",
        "        CUDA_VERSION = torch.version.cuda\n",
        "        CUDA_STR = f\"cu{CUDA_VERSION.replace('.', '')}\" if CUDA_VERSION else 'cpu'\n",
        "        print(f\"Detected PyTorch {TORCH_VERSION} and device type {CUDA_STR}.\")\n",
        "        PYG_URL = f'https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_STR}.html'\n",
        "        pyg_packages = ['torch-scatter', 'torch-sparse', 'torch-cluster', 'torch-geometric']\n",
        "        for package in pyg_packages:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package, '-f', PYG_URL])\n",
        "        print(\"--- All dependencies installed successfully. ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to install PyG packages: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "install_packages()\n",
        "\n",
        "# --- Step 2: Imports and Global Configuration ---\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINConv, global_add_pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
        "from chembl_webresource_client.new_client import new_client\n",
        "import selfies as sf\n",
        "import requests\n",
        "\n",
        "# --- Configuration for ChEMBL ---\n",
        "PROPERTIES_TO_PREDICT = ['pchembl_value', 'logp', 'molecular_weight']\n",
        "N_PROPERTIES = len(PROPERTIES_TO_PREDICT)\n",
        "N_MOLECULES_GNN = 10000\n",
        "N_MOLECULES_RNN = 20000\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "N_EPOCHS_GNN = 50\n",
        "N_EPOCHS_RNN = 30\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Step 3: Define Helper Functions ---\n",
        "\n",
        "def get_chembl_data(target_id='CHEMBL203', min_pchembl=5.0):\n",
        "    \"\"\"Downloads and processes bioactivity data from ChEMBL for a specific target.\"\"\"\n",
        "    print(f\"--- Downloading data for target {target_id} from ChEMBL ---\")\n",
        "    activity = new_client.activity\n",
        "    res = activity.filter(target_chembl_id=target_id, standard_type=\"IC50\", pchembl_value__gte=min_pchembl)\n",
        "    df = pd.DataFrame(res)\n",
        "\n",
        "    print(\"these is the head of the dataset: before processing\")\n",
        "    print(df.head())\n",
        "\n",
        "    df = df[['canonical_smiles', 'pchembl_value']]\n",
        "    df = df.dropna().drop_duplicates(subset=['canonical_smiles'])\n",
        "    df['pchembl_value'] = pd.to_numeric(df['pchembl_value'])\n",
        "\n",
        "    print(f\"Downloaded and cleaned {len(df)} unique, active compounds.\")\n",
        "\n",
        "    molecules = [Chem.MolFromSmiles(smi) for smi in df['canonical_smiles']]\n",
        "    df['logp'] = [Descriptors.MolLogP(m) if m else None for m in molecules]\n",
        "    df['molecular_weight'] = [Descriptors.MolWt(m) if m else None for m in molecules]\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    print(\"these is the head of the dataset: after processing\")\n",
        "    print(df.head())\n",
        "\n",
        "    df = df.rename(columns={'canonical_smiles': 'smiles'})\n",
        "    print(f\"Processed down to {len(df)} compounds with all required properties.\")\n",
        "    return df\n",
        "\n",
        "def smiles_to_graph(smiles: str):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None: return None\n",
        "    atom_features = [[\n",
        "        atom.GetAtomicNum(), atom.GetFormalCharge(), float(atom.GetHybridization()),\n",
        "        float(atom.GetIsAromatic()), atom.GetTotalNumHs(), atom.GetTotalValence()\n",
        "    ] for atom in mol.GetAtoms()]\n",
        "    x = torch.tensor(atom_features, dtype=torch.float)\n",
        "    if mol.GetNumBonds() > 0:\n",
        "        row, col = [], []\n",
        "        for bond in mol.GetBonds():\n",
        "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "            row.extend([start, end]); col.extend([end, start])\n",
        "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "    else:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "def evaluate_multitask_gnn(loader, model, scalers):\n",
        "    \"\"\"Evaluates the Multi-Task GNN and returns MAE for each property.\"\"\"\n",
        "    model.eval()\n",
        "    predictions, targets_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(DEVICE)\n",
        "            out = model(batch)\n",
        "            predictions.append(out.cpu().numpy())\n",
        "            targets_list.append(batch.y.cpu().numpy())\n",
        "\n",
        "    predictions = np.vstack(predictions)\n",
        "\n",
        "    # SHAPE ERROR FIX: Concatenate the list of flat target arrays and then reshape\n",
        "    targets = np.concatenate(targets_list).reshape(predictions.shape)\n",
        "\n",
        "    maes = {}\n",
        "    for i, prop in enumerate(PROPERTIES_TO_PREDICT):\n",
        "        pred_real = scalers[prop].inverse_transform(predictions[:, i].reshape(-1, 1)).flatten()\n",
        "        targ_real = scalers[prop].inverse_transform(targets[:, i].reshape(-1, 1)).flatten()\n",
        "        maes[prop] = np.mean(np.abs(pred_real - targ_real))\n",
        "    return maes\n",
        "\n",
        "\n",
        "def analyze_novel_molecule_robust(smiles: str):\n",
        "    results = {\"Complexity_Score\": \"N/A\", \"Flags\": []}\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if not mol: return results\n",
        "        num_rings = rdMolDescriptors.CalcNumRings(mol)\n",
        "        num_spiro = rdMolDescriptors.CalcNumSpiroAtoms(mol)\n",
        "        num_bridgehead = rdMolDescriptors.CalcNumBridgeheadAtoms(mol)\n",
        "        complexity_score = (num_rings * 1.0 + num_spiro * 2.5 + num_bridgehead * 2.5)\n",
        "        results[\"Complexity_Score\"] = f\"{complexity_score:.2f}\"\n",
        "    except: pass\n",
        "    return results\n",
        "\n",
        "def suggest_drug_candidate_potential(predicted_properties: dict, calculated_properties: dict):\n",
        "    \"\"\"Provides a detailed, multi-level assessment of a molecule's drug potential.\"\"\"\n",
        "    insights, flags = [], []\n",
        "    pchembl = predicted_properties.get('pchembl_value', 0)\n",
        "    logp = predicted_properties.get('logp', 99)\n",
        "    mw = predicted_properties.get('molecular_weight', 999)\n",
        "\n",
        "    if pchembl >= 8.0: insights.append(\"Exceptional Potency (Lead Candidate)\")\n",
        "    elif pchembl >= 7.0: insights.append(\"High Potency (Strong Hit)\")\n",
        "    elif pchembl >= 6.0: insights.append(\"Good Potency (Promising Hit)\")\n",
        "    elif pchembl >= 5.0: insights.append(\"Active (Hit, Needs Optimization)\")\n",
        "    else: flags.append(\"Low Predicted Potency\")\n",
        "\n",
        "    if mw > 500: flags.append(\"Poor Oral Bioavailability (MW > 500)\")\n",
        "    elif mw < 200: insights.append(\"Fragment-like Size (Good for Fragment-Based Design)\")\n",
        "    else: insights.append(\"Ideal Drug-like Size\")\n",
        "\n",
        "    if logp > 5.0: flags.append(\"Poor Solubility (logP > 5)\")\n",
        "    elif logp < 0: flags.append(\"Too Polar (Poor Permeability)\")\n",
        "    elif 1.0 <= logp <= 3.5: insights.append(\"Optimal Solubility Profile\")\n",
        "    else: insights.append(\"Acceptable Solubility\")\n",
        "\n",
        "    if not flags and \"High Potency\" in \" \".join(insights) and \"Ideal\" in \" \".join(insights):\n",
        "        final_assessment = \"STRONG CANDIDATE: \" + \", \".join(insights)\n",
        "    elif not flags and \"Promising\" in \" \".join(insights):\n",
        "        final_assessment = \"PROMISING CANDIDATE: \" + \", \".join(insights)\n",
        "    else:\n",
        "        final_assessment = \", \".join(insights)\n",
        "\n",
        "    if flags:\n",
        "        final_assessment += \" | FLAGS: \" + \", \".join(flags)\n",
        "\n",
        "    return final_assessment if final_assessment else \"General Bioactive Compound\"\n",
        "\n",
        "# --- Step 4: Define Model Architectures ---\n",
        "class MultiTaskGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, out_dim=3):\n",
        "        super().__init__()\n",
        "        nn1 = nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))\n",
        "        self.conv1 = GINConv(nn1)\n",
        "        nn2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))\n",
        "        self.conv2 = GINConv(nn2)\n",
        "        self.lin1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.lin2 = nn.Linear(hidden_dim, out_dim)\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index).relu()\n",
        "        x = global_add_pool(x, batch)\n",
        "        x = self.lin1(x).relu()\n",
        "        return self.lin2(x)\n",
        "\n",
        "class SELFIES_RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size=128, hidden_size=512, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "    def forward(self, x, hidden=None):\n",
        "        emb = self.embedding(x); out, hidden = self.rnn(emb, hidden)\n",
        "        return self.fc(out), hidden\n",
        "\n",
        "def sample_selfies(model, token2idx, idx2token, max_len=50, temperature=1.0):\n",
        "    model.eval()\n",
        "    start_token = '[C]'\n",
        "    x = torch.tensor([[token2idx[start_token]]], device=DEVICE)\n",
        "    hidden = None\n",
        "    tokens = [start_token]\n",
        "    for _ in range(max_len):\n",
        "        out, hidden = model(x, hidden)\n",
        "        probs = F.softmax(out.squeeze() / temperature, dim=-1)\n",
        "        idx = torch.multinomial(probs, 1).item()\n",
        "        if idx == 0: break\n",
        "        tokens.append(idx2token[idx])\n",
        "        x = torch.tensor([[idx]], device=DEVICE)\n",
        "    try: return sf.decoder(''.join(tokens))\n",
        "    except: return None\n",
        "\n",
        "# =============================================================================\n",
        "# Main Execution Block\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"\\nProject starting on device: {DEVICE}\\n\")\n",
        "    df_main = get_chembl_data()\n",
        "\n",
        "    print(\"\\n--- 1. Preparing Data for Multi-Task GNN ---\")\n",
        "    gnn_data_list = []\n",
        "    subset_df_gnn = df_main.head(N_MOLECULES_GNN)\n",
        "    for _, row in tqdm(subset_df_gnn.iterrows(), total=subset_df_gnn.shape[0], desc=\"Creating GNN graphs\"):\n",
        "        graph = smiles_to_graph(row['smiles'])\n",
        "        if graph:\n",
        "            graph.y = torch.tensor([row[p] for p in PROPERTIES_TO_PREDICT], dtype=torch.float)\n",
        "            graph.smiles = row['smiles']\n",
        "            gnn_data_list.append(graph)\n",
        "\n",
        "    train_val_data, test_data = train_test_split(gnn_data_list, test_size=0.15, random_state=42)\n",
        "    train_data, val_data = train_test_split(train_val_data, test_size=0.17, random_state=42)\n",
        "\n",
        "    scalers = {}\n",
        "    for i, prop in enumerate(PROPERTIES_TO_PREDICT):\n",
        "        targets = np.array([d.y[i].item() for d in train_data]).reshape(-1, 1)\n",
        "        scalers[prop] = StandardScaler().fit(targets)\n",
        "        for d in train_val_data + test_data:\n",
        "            d.y[i] = torch.tensor(scalers[prop].transform([[d.y[i].item()]])[0,0])\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
        "    print(f\"Data split: {len(train_data)} train, {len(val_data)} validation, {len(test_data)} test.\")\n",
        "\n",
        "    print(\"\\n--- 2. Training Multi-Task Predictive GNN ---\")\n",
        "    gnn_model = MultiTaskGNN(in_dim=train_data[0].num_node_features, out_dim=N_PROPERTIES).to(DEVICE)\n",
        "    optimizer_gnn = torch.optim.Adam(gnn_model.parameters(), lr=LEARNING_RATE)\n",
        "    loss_fn_gnn = nn.MSELoss()\n",
        "    best_val_mae_sum = float('inf')\n",
        "    for epoch in range(1, N_EPOCHS_GNN + 1):\n",
        "        gnn_model.train()\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(DEVICE); optimizer_gnn.zero_grad()\n",
        "            out = gnn_model(batch)\n",
        "            target = batch.y.view_as(out)\n",
        "            loss = loss_fn_gnn(out, target)\n",
        "            loss.backward(); optimizer_gnn.step()\n",
        "        val_maes = evaluate_multitask_gnn(val_loader, gnn_model, scalers)\n",
        "        current_mae_sum = sum(val_maes.values())\n",
        "        if current_mae_sum < best_val_mae_sum:\n",
        "            best_val_mae_sum = current_mae_sum\n",
        "            torch.save(gnn_model.state_dict(), 'best_gnn_model.pth')\n",
        "        print(f\"GNN Epoch {epoch:02d} | Val MAEs: \" + \", \".join([f\"{k[:10]}={v:.3f}\" for k,v in val_maes.items()]))\n",
        "\n",
        "    gnn_model.load_state_dict(torch.load('best_gnn_model.pth'))\n",
        "\n",
        "    print(\"\\n--- 3. Training Generative RNN ---\")\n",
        "    selfies_list = [sf.encoder(smi) for smi in tqdm(df_main['smiles'].head(N_MOLECULES_RNN), desc=\"Encoding to SELFIES\") if smi and sf.encoder(smi)]\n",
        "    all_tokens = set(t for s in selfies_list for t in sf.split_selfies(s))\n",
        "    token2idx = {t: i + 1 for i, t in enumerate(sorted(all_tokens))}; token2idx['<PAD>'] = 0\n",
        "    idx2token = {i: t for t, i in token2idx.items()}; vocab_size = len(token2idx)\n",
        "    max_len = max(len(list(sf.split_selfies(s))) for s in selfies_list if s)\n",
        "    selfies_tensor = torch.stack([torch.tensor([token2idx.get(t, 0) for t in list(sf.split_selfies(s))] + [0] * (max_len - len(list(sf.split_selfies(s)))), dtype=torch.long) for s in selfies_list])\n",
        "    rnn_dataset = torch.utils.data.TensorDataset(selfies_tensor[:, :-1], selfies_tensor[:, 1:])\n",
        "    rnn_loader = DataLoader(rnn_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "    rnn_model = SELFIES_RNN(vocab_size).to(DEVICE)\n",
        "    opt_rnn = torch.optim.Adam(rnn_model.parameters(), lr=1e-3)\n",
        "    for epoch in range(1, N_EPOCHS_RNN + 1):\n",
        "        rnn_model.train()\n",
        "        for x, y in rnn_loader:\n",
        "            # CORRECTED LINE: Move both x and y to the device\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            opt_rnn.zero_grad()\n",
        "            out, _ = rnn_model(x)\n",
        "            loss = F.cross_entropy(out.reshape(-1, vocab_size), y.reshape(-1), ignore_index=0)\n",
        "            loss.backward()\n",
        "            opt_rnn.step()\n",
        "        print(f\"RNN Epoch {epoch:02d}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"                    FINAL DRUG DISCOVERY ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\n--- A. GNN PERFORMANCE ON UNSEEN TEST DATA ---\")\n",
        "    test_maes = evaluate_multitask_gnn(test_loader, gnn_model, scalers)\n",
        "    for prop, mae in test_maes.items():\n",
        "        print(f\"  - MAE for {prop:<20}: {mae:.4f}\")\n",
        "\n",
        "    print(\"\\n--- B. DRUG CANDIDATE ANALYSIS OF NOVEL MOLECULES ---\")\n",
        "    generated_smiles = [sample_selfies(rnn_model, token2idx, idx2token, temperature=0.95) for _ in tqdm(range(200), desc=\"Generating Molecules\")]\n",
        "    valid_smiles = [s for s in generated_smiles if s and Chem.MolFromSmiles(s)]\n",
        "    novel_molecules_smiles = valid_smiles\n",
        "\n",
        "    if novel_molecules_smiles:\n",
        "        novel_graphs = [smiles_to_graph(s) for s in novel_molecules_smiles]\n",
        "        valid_novel_graphs_data = [(smi, g) for smi, g in zip(novel_molecules_smiles, novel_graphs) if g is not None]\n",
        "\n",
        "        if valid_novel_graphs_data:\n",
        "            smiles_for_analysis = [smi for smi, g in valid_novel_graphs_data]\n",
        "            graphs_for_analysis = [g for smi, g in valid_novel_graphs_data]\n",
        "            predict_loader = DataLoader(graphs_for_analysis, batch_size=len(graphs_for_analysis))\n",
        "            batch = next(iter(predict_loader)).to(DEVICE)\n",
        "            preds_scaled_novel = gnn_model(batch).cpu().detach().numpy()\n",
        "\n",
        "            analysis_results = []\n",
        "            for i, smiles in enumerate(smiles_for_analysis):\n",
        "                predicted_props = {prop: scalers[prop].inverse_transform(preds_scaled_novel[i, j].reshape(1, -1))[0,0] for j, prop in enumerate(PROPERTIES_TO_PREDICT)}\n",
        "                complexity_data = analyze_novel_molecule_robust(smiles)\n",
        "                assessment = suggest_drug_candidate_potential(predicted_props, complexity_data)\n",
        "\n",
        "                analysis_results.append([\n",
        "                    smiles,\n",
        "                    f\"{predicted_props['pchembl_value']:.2f}\",\n",
        "                    f\"{predicted_props['logp']:.2f}\",\n",
        "                    f\"{predicted_props['molecular_weight']:.2f}\",\n",
        "                    complexity_data[\"Complexity_Score\"],\n",
        "                    assessment\n",
        "                ])\n",
        "\n",
        "            headers = [\"Novel SMILES\", \"Pred. pChEMBL\", \"Pred. logP\", \"Pred. MW\", \"Complexity Score\", \"Drug Candidate Assessment\"]\n",
        "            df_analysis = pd.DataFrame(analysis_results, columns=headers)\n",
        "            print(df_analysis.head(15).to_string(index=False))\n",
        "    else:\n",
        "        print(\"No valid novel molecules were generated to analyze.\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"                              PROJECT COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv_9f0ZJM1--",
        "outputId": "6b71aeee-e28c-4abe-efae-5cbd6c859909"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking and installing dependencies ---\n",
            "Detected PyTorch 2.8.0 and device type cu126.\n",
            "--- All dependencies installed successfully. ---\n",
            "\n",
            "Project starting on device: cuda\n",
            "\n",
            "--- Downloading data for target CHEMBL203 from ChEMBL ---\n",
            "these is the head of the dataset: before processing\n",
            "  action_type activity_comment  activity_id activity_properties  \\\n",
            "0        None             None        32260                  []   \n",
            "1        None             None        32263                  []   \n",
            "2        None             None        32265                  []   \n",
            "3        None             None        32267                  []   \n",
            "4        None             None        32270                  []   \n",
            "\n",
            "  assay_chembl_id                                  assay_description  \\\n",
            "0    CHEMBL674637  Inhibitory activity towards tyrosine phosphory...   \n",
            "1    CHEMBL621151  Inhibition of autophosphorylation of human epi...   \n",
            "2    CHEMBL615325  Inhibition of ligand-induced proliferation in ...   \n",
            "3    CHEMBL674637  Inhibitory activity towards tyrosine phosphory...   \n",
            "4    CHEMBL621151  Inhibition of autophosphorylation of human epi...   \n",
            "\n",
            "  assay_type assay_variant_accession assay_variant_mutation bao_endpoint  ...  \\\n",
            "0          B                    None                   None  BAO_0000190  ...   \n",
            "1          F                    None                   None  BAO_0000190  ...   \n",
            "2          F                    None                   None  BAO_0000190  ...   \n",
            "3          B                    None                   None  BAO_0000190  ...   \n",
            "4          F                    None                   None  BAO_0000190  ...   \n",
            "\n",
            "  target_organism                  target_pref_name target_tax_id text_value  \\\n",
            "0    Homo sapiens  Epidermal growth factor receptor          9606       None   \n",
            "1    Homo sapiens  Epidermal growth factor receptor          9606       None   \n",
            "2    Homo sapiens  Epidermal growth factor receptor          9606       None   \n",
            "3    Homo sapiens  Epidermal growth factor receptor          9606       None   \n",
            "4    Homo sapiens  Epidermal growth factor receptor          9606       None   \n",
            "\n",
            "   toid  type units    uo_units upper_value  value  \n",
            "0  None  IC50    uM  UO_0000065        None  0.041  \n",
            "1  None  IC50    uM  UO_0000065        None    0.3  \n",
            "2  None  IC50    uM  UO_0000065        None   7.82  \n",
            "3  None  IC50    uM  UO_0000065        None   0.17  \n",
            "4  None  IC50    uM  UO_0000065        None   0.04  \n",
            "\n",
            "[5 rows x 46 columns]\n",
            "Downloaded and cleaned 9739 unique, active compounds.\n",
            "these is the head of the dataset: after processing\n",
            "                                    canonical_smiles  pchembl_value     logp  \\\n",
            "0  Cc1cc(C)c(/C=C2\\C(=O)Nc3ncnc(Nc4ccc(F)c(Cl)c4)...           7.39  4.45034   \n",
            "3  Cc1cc(C(=O)N2CCOCC2)[nH]c1/C=C1\\C(=O)Nc2ncnc(N...           6.77  3.61432   \n",
            "6        CN(c1ccccc1)c1ncnc2ccc(N/N=N/Cc3ccccn3)cc12           5.03  4.77200   \n",
            "7  Cc1cc(C(=O)NCCN2CCOCC2)[nH]c1/C=C1\\C(=O)N(C)c2...           5.28  3.22822   \n",
            "8                N#CC(C#N)=C(N)/C(C#N)=C/c1ccc(O)cc1           6.90  1.55914   \n",
            "\n",
            "   molecular_weight  \n",
            "0           383.814  \n",
            "3           482.903  \n",
            "6           369.432  \n",
            "7           539.999  \n",
            "8           236.234  \n",
            "Processed down to 9739 compounds with all required properties.\n",
            "\n",
            "--- 1. Preparing Data for Multi-Task GNN ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating GNN graphs: 100%|██████████| 9739/9739 [00:10<00:00, 923.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split: 6870 train, 1408 validation, 1461 test.\n",
            "\n",
            "--- 2. Training Multi-Task Predictive GNN ---\n",
            "GNN Epoch 01 | Val MAEs: pchembl_va=0.860, logp=0.718, molecular_=57.237\n",
            "GNN Epoch 02 | Val MAEs: pchembl_va=0.927, logp=0.631, molecular_=51.264\n",
            "GNN Epoch 03 | Val MAEs: pchembl_va=0.824, logp=0.575, molecular_=47.355\n",
            "GNN Epoch 04 | Val MAEs: pchembl_va=0.938, logp=0.679, molecular_=48.644\n",
            "GNN Epoch 05 | Val MAEs: pchembl_va=0.799, logp=0.578, molecular_=42.336\n",
            "GNN Epoch 06 | Val MAEs: pchembl_va=0.841, logp=0.653, molecular_=39.121\n",
            "GNN Epoch 07 | Val MAEs: pchembl_va=0.789, logp=0.513, molecular_=37.571\n",
            "GNN Epoch 08 | Val MAEs: pchembl_va=0.748, logp=0.490, molecular_=33.774\n",
            "GNN Epoch 09 | Val MAEs: pchembl_va=0.757, logp=0.450, molecular_=34.491\n",
            "GNN Epoch 10 | Val MAEs: pchembl_va=0.898, logp=0.483, molecular_=35.277\n",
            "GNN Epoch 11 | Val MAEs: pchembl_va=0.720, logp=0.547, molecular_=33.798\n",
            "GNN Epoch 12 | Val MAEs: pchembl_va=0.773, logp=0.659, molecular_=33.064\n",
            "GNN Epoch 13 | Val MAEs: pchembl_va=0.720, logp=0.429, molecular_=33.521\n",
            "GNN Epoch 14 | Val MAEs: pchembl_va=0.702, logp=0.370, molecular_=27.437\n",
            "GNN Epoch 15 | Val MAEs: pchembl_va=0.786, logp=0.494, molecular_=27.220\n",
            "GNN Epoch 16 | Val MAEs: pchembl_va=0.706, logp=0.349, molecular_=26.662\n",
            "GNN Epoch 17 | Val MAEs: pchembl_va=0.738, logp=0.389, molecular_=28.284\n",
            "GNN Epoch 18 | Val MAEs: pchembl_va=0.682, logp=0.328, molecular_=26.492\n",
            "GNN Epoch 19 | Val MAEs: pchembl_va=0.695, logp=0.318, molecular_=23.670\n",
            "GNN Epoch 20 | Val MAEs: pchembl_va=0.673, logp=0.455, molecular_=24.331\n",
            "GNN Epoch 21 | Val MAEs: pchembl_va=0.704, logp=0.390, molecular_=23.947\n",
            "GNN Epoch 22 | Val MAEs: pchembl_va=0.662, logp=0.364, molecular_=23.017\n",
            "GNN Epoch 23 | Val MAEs: pchembl_va=0.687, logp=0.310, molecular_=21.272\n",
            "GNN Epoch 24 | Val MAEs: pchembl_va=0.668, logp=0.294, molecular_=24.846\n",
            "GNN Epoch 25 | Val MAEs: pchembl_va=0.661, logp=0.296, molecular_=21.807\n",
            "GNN Epoch 26 | Val MAEs: pchembl_va=0.663, logp=0.296, molecular_=20.058\n",
            "GNN Epoch 27 | Val MAEs: pchembl_va=0.662, logp=0.288, molecular_=23.795\n",
            "GNN Epoch 28 | Val MAEs: pchembl_va=0.655, logp=0.401, molecular_=18.833\n",
            "GNN Epoch 29 | Val MAEs: pchembl_va=0.670, logp=0.274, molecular_=19.913\n",
            "GNN Epoch 30 | Val MAEs: pchembl_va=0.656, logp=0.291, molecular_=23.557\n",
            "GNN Epoch 31 | Val MAEs: pchembl_va=0.646, logp=0.285, molecular_=18.417\n",
            "GNN Epoch 32 | Val MAEs: pchembl_va=0.658, logp=0.488, molecular_=24.181\n",
            "GNN Epoch 33 | Val MAEs: pchembl_va=0.671, logp=0.284, molecular_=25.466\n",
            "GNN Epoch 34 | Val MAEs: pchembl_va=0.649, logp=0.334, molecular_=18.136\n",
            "GNN Epoch 35 | Val MAEs: pchembl_va=0.645, logp=0.234, molecular_=18.578\n",
            "GNN Epoch 36 | Val MAEs: pchembl_va=0.658, logp=0.576, molecular_=20.149\n",
            "GNN Epoch 37 | Val MAEs: pchembl_va=0.629, logp=0.258, molecular_=16.498\n",
            "GNN Epoch 38 | Val MAEs: pchembl_va=0.646, logp=0.542, molecular_=17.669\n",
            "GNN Epoch 39 | Val MAEs: pchembl_va=0.633, logp=0.274, molecular_=16.958\n",
            "GNN Epoch 40 | Val MAEs: pchembl_va=0.656, logp=0.284, molecular_=16.899\n",
            "GNN Epoch 41 | Val MAEs: pchembl_va=0.642, logp=0.244, molecular_=15.446\n",
            "GNN Epoch 42 | Val MAEs: pchembl_va=0.638, logp=0.537, molecular_=23.416\n",
            "GNN Epoch 43 | Val MAEs: pchembl_va=0.616, logp=0.265, molecular_=22.022\n",
            "GNN Epoch 44 | Val MAEs: pchembl_va=0.616, logp=0.278, molecular_=14.726\n",
            "GNN Epoch 45 | Val MAEs: pchembl_va=0.637, logp=0.254, molecular_=16.073\n",
            "GNN Epoch 46 | Val MAEs: pchembl_va=0.680, logp=0.266, molecular_=16.192\n",
            "GNN Epoch 47 | Val MAEs: pchembl_va=0.705, logp=0.365, molecular_=15.728\n",
            "GNN Epoch 48 | Val MAEs: pchembl_va=0.627, logp=0.222, molecular_=15.776\n",
            "GNN Epoch 49 | Val MAEs: pchembl_va=0.613, logp=0.222, molecular_=20.575\n",
            "GNN Epoch 50 | Val MAEs: pchembl_va=0.605, logp=0.218, molecular_=14.174\n",
            "\n",
            "--- 3. Training Generative RNN ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding to SELFIES: 100%|██████████| 9739/9739 [00:09<00:00, 1053.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN Epoch 01, Loss: 2.0646\n",
            "RNN Epoch 02, Loss: 1.5604\n",
            "RNN Epoch 03, Loss: 1.2316\n",
            "RNN Epoch 04, Loss: 1.0630\n",
            "RNN Epoch 05, Loss: 0.9073\n",
            "RNN Epoch 06, Loss: 0.8361\n",
            "RNN Epoch 07, Loss: 0.7683\n",
            "RNN Epoch 08, Loss: 0.7028\n",
            "RNN Epoch 09, Loss: 0.6762\n",
            "RNN Epoch 10, Loss: 0.6468\n",
            "RNN Epoch 11, Loss: 0.5853\n",
            "RNN Epoch 12, Loss: 0.5824\n",
            "RNN Epoch 13, Loss: 0.5381\n",
            "RNN Epoch 14, Loss: 0.5292\n",
            "RNN Epoch 15, Loss: 0.4640\n",
            "RNN Epoch 16, Loss: 0.4703\n",
            "RNN Epoch 17, Loss: 0.4281\n",
            "RNN Epoch 18, Loss: 0.4276\n",
            "RNN Epoch 19, Loss: 0.4146\n",
            "RNN Epoch 20, Loss: 0.4197\n",
            "RNN Epoch 21, Loss: 0.3632\n",
            "RNN Epoch 22, Loss: 0.3891\n",
            "RNN Epoch 23, Loss: 0.3774\n",
            "RNN Epoch 24, Loss: 0.3621\n",
            "RNN Epoch 25, Loss: 0.3622\n",
            "RNN Epoch 26, Loss: 0.3591\n",
            "RNN Epoch 27, Loss: 0.3360\n",
            "RNN Epoch 28, Loss: 0.3445\n",
            "RNN Epoch 29, Loss: 0.3258\n",
            "RNN Epoch 30, Loss: 0.3271\n",
            "\n",
            "================================================================================\n",
            "                    FINAL DRUG DISCOVERY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "--- A. GNN PERFORMANCE ON UNSEEN TEST DATA ---\n",
            "  - MAE for pchembl_value       : 0.6167\n",
            "  - MAE for logp                : 0.2194\n",
            "  - MAE for molecular_weight    : 14.2096\n",
            "\n",
            "--- B. DRUG CANDIDATE ANALYSIS OF NOVEL MOLECULES ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Molecules: 100%|██████████| 200/200 [00:06<00:00, 28.95it/s]\n",
            "[08:59:22] Explicit valence for atom # 23 Br, 3, is greater than permitted\n",
            "[08:59:22] Explicit valence for atom # 26 Br, 2, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   Novel SMILES Pred. pChEMBL Pred. logP Pred. MW Complexity Score                                                                                 Drug Candidate Assessment\n",
            "               C1=CC(=O)NC=CCC=C1NC2=NC(NC3=CC=CC=C3)=NC=C2CC=C          5.77       4.02   391.36             3.00                             Active (Hit, Needs Optimization), Ideal Drug-like Size, Acceptable Solubility\n",
            "            COC=CC(Cl)=CC(=C)OC=NONCC1=CC=C(Cl)C=C1C=CNC=CC=CCC          4.68       3.91   364.96             1.00                                Ideal Drug-like Size, Acceptable Solubility | FLAGS: Low Predicted Potency\n",
            "                            CCCCCCNC(=O)COC=C1C(NCC2=CC=CC12)=N          6.76       2.99   420.07             2.00       PROMISING CANDIDATE: Good Potency (Promising Hit), Ideal Drug-like Size, Optimal Solubility Profile\n",
            "      C1OCCOC=CC=NC=NC1(NC=C2C=C(OCC3=CC=CC=C3OC)C(Cl)=C2C)C=CN          7.74       2.09   425.80             3.00             STRONG CANDIDATE: High Potency (Strong Hit), Ideal Drug-like Size, Optimal Solubility Profile\n",
            "         C1C=2[NH1]C3=NC=NC(NC4=CC=CC(Cl)=C4)=C3C=2C5=CC=CC=C51          6.88       5.38   387.17             5.00                    Good Potency (Promising Hit), Ideal Drug-like Size | FLAGS: Poor Solubility (logP > 5)\n",
            "            COC=CC=COC=CC=C(NS(=O)(=O)C1=CC=CC=C1OC(F)(F)F)C=CN          6.48       2.34   384.16             1.00       PROMISING CANDIDATE: Good Potency (Promising Hit), Ideal Drug-like Size, Optimal Solubility Profile\n",
            "     C=1OC2=CC3=C(NC4=CC=CC(Br)=C4)N=CN=C3C=C2OCCCN5CCOCC5C=C=1          8.14       4.56   507.19             5.00 Exceptional Potency (Lead Candidate), Acceptable Solubility | FLAGS: Poor Oral Bioavailability (MW > 500)\n",
            "             COC=C1C(NCCC(C(N)=O)C(N)C)CC1=CC=CNC=NC=C(Cl)CNC=C          4.53       1.53   434.82             1.00                           Ideal Drug-like Size, Optimal Solubility Profile | FLAGS: Low Predicted Potency\n",
            "       CCS(=O)(=O)NC=CC=CN=CN=CNC=CC=C(OC1=CC=CC(C(F)(F)F)=C1)C          5.31       2.89   376.29             1.00                        Active (Hit, Needs Optimization), Ideal Drug-like Size, Optimal Solubility Profile\n",
            "     COC1=CC=CC=C1C(=O)NCC=CC=CC=NN(CCCC(CO)C)C=CC=NC=NC(N2)=C2          6.55       1.60   422.15             2.00       PROMISING CANDIDATE: Good Potency (Promising Hit), Ideal Drug-like Size, Optimal Solubility Profile\n",
            "    C=CC(=O)NC=CC=CCNC=NC(NC1=CC=C(OCC2=CC=CN=C2)C(Cl)=C1)=NC=C          6.25       3.88   418.55             2.00            PROMISING CANDIDATE: Good Potency (Promising Hit), Ideal Drug-like Size, Acceptable Solubility\n",
            "COC=NC=CC=C[C@H1]NC=CC(Cl)=C1N=CC(C#N)=C(NC2=CC=C(F)C(Cl)=C2)C1          7.83       3.66   450.29             2.00                  STRONG CANDIDATE: High Potency (Strong Hit), Ideal Drug-like Size, Acceptable Solubility\n",
            " CN(C)CCCNCC=CC=CC(=O)N[C@@H1][C@H1]OC=CC=COC1=CC=NC=C1CCC(=O)N          6.79       1.33   453.38             1.00       PROMISING CANDIDATE: Good Potency (Promising Hit), Ideal Drug-like Size, Optimal Solubility Profile\n",
            "     C=C=CC(=O)NC=CC(NC=NC=C(OC)C(C1=CN(C)C2=CC=CC=C12)=N)(OC)C          7.02       0.91   402.75             2.00                  STRONG CANDIDATE: High Potency (Strong Hit), Ideal Drug-like Size, Acceptable Solubility\n",
            "        CCC(=O)NCC[C@H1]NC(=O)N(C1=CC=CC=C1F)CC=CN=CNC=CC=CNCCN          3.47       1.42   408.37             1.00                           Ideal Drug-like Size, Optimal Solubility Profile | FLAGS: Low Predicted Potency\n",
            "\n",
            "================================================================================\n",
            "                              PROJECT COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "#                  Final Project Statistical Summary\n",
        "# =============================================================================\n",
        "#\n",
        "# Objective:\n",
        "# To provide a comprehensive, \"full-fledged\" summary of the entire project's\n",
        "# performance, validating both the predictive GNN and the generative RNN\n",
        "# with key statistics from the training and generation phases.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# This cell assumes that all variables from the main pipeline script are in memory.\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"                    NOVA-MOL PROJECT: FINAL STATISTICAL REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# --- 1. Dataset & Training Configuration ---\n",
        "print(\"\\n--- 1. DATASET & TRAINING CONFIGURATION ---\")\n",
        "# Ensure variables exist before printing\n",
        "if 'DEVICE' in locals():\n",
        "    print(f\"  - AI Target Device:                  {str(DEVICE).upper()}\")\n",
        "if 'train_data' in locals():\n",
        "    print(f\"  - GNN Training Molecules:            {len(train_data)}\")\n",
        "if 'val_data' in locals():\n",
        "    print(f\"  - GNN Validation Molecules:          {len(val_data)}\")\n",
        "if 'test_data' in locals():\n",
        "    print(f\"  - GNN Test Molecules:                {len(test_data)}\")\n",
        "if 'N_EPOCHS_GNN' in locals():\n",
        "    print(f\"  - GNN Training Epochs:               {N_EPOCHS_GNN}\")\n",
        "if 'selfies_list' in locals():\n",
        "    print(f\"  --------------------------------------------------\")\n",
        "    print(f\"  - RNN Training Molecules:            {len(selfies_list)}\")\n",
        "if 'N_EPOCHS_RNN' in locals():\n",
        "    print(f\"  - RNN Training Epochs:               {N_EPOCHS_RNN}\")\n",
        "\n",
        "\n",
        "# --- 2. Predictive Model (GNN) Validation ---\n",
        "print(\"\\n--- 2. PREDICTIVE GNN MODEL VALIDATION ---\")\n",
        "print(\"The GNN's performance was rigorously validated on the held-out, unseen Test Set.\")\n",
        "print(\"The Mean Absolute Error (MAE) measures the average error of our predictions.\")\n",
        "print(\"\\n  **Final GNN Performance on Test Set:**\")\n",
        "if 'test_maes' in locals():\n",
        "    for prop, mae in test_maes.items():\n",
        "        print(f\"    - MAE for {prop:<20}: {mae:.4f}\")\n",
        "else:\n",
        "    print(\"    - GNN test performance data not available.\")\n",
        "\n",
        "\n",
        "# --- 3. Generative Model (RNN) Validation ---\n",
        "print(\"\\n--- 3. GENERATIVE RNN MODEL VALIDATION ---\")\n",
        "print(\"The RNN's performance is validated by the quality and novelty of the molecules it creates.\")\n",
        "\n",
        "if 'valid_smiles' in locals():\n",
        "    total_generated = len(valid_smiles)\n",
        "    num_novel = len(novel_molecules_smiles) # In this script, novel_molecules_smiles is currently all valid_smiles\n",
        "\n",
        "    print(f\"\\n  **Generation Statistics:**\")\n",
        "    print(f\"    - Total Valid Molecules Generated:   {total_generated}\")\n",
        "    # The novelty check against existing molecules (e.g., PubChem) is not implemented.\n",
        "    # Reporting 'Novel Molecules Discovered' based on just the valid generated count\n",
        "    # as the comparison to an existing database is not performed.\n",
        "    print(f\"    - Novel Molecules Reported:          {num_novel} (Note: No external novelty check performed)\")\n",
        "\n",
        "    if num_novel > 0:\n",
        "        print(\"\\n  **Conclusion:** The RNN has successfully generated valid molecular structures.\")\n",
        "        print(\"  Further analysis (e.g., external database search for novelty, in vitro testing)\")\n",
        "        print(\"  is required to confirm true novelty and potential as drug candidates.\")\n",
        "    else:\n",
        "         print(\"\\n  **Conclusion:** The RNN did not generate any valid molecules in this run.\")\n",
        "else:\n",
        "    print(\"\\n  **Generation Statistics:**\")\n",
        "    print(\"    - No valid molecules were generated in this run.\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"                              END OF REPORT\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye23bpqKUMKz",
        "outputId": "0fac6f8d-fb2b-4a4a-c92b-b0aa942c9f3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "                    NOVA-MOL PROJECT: FINAL STATISTICAL REPORT\n",
            "================================================================================\n",
            "\n",
            "--- 1. DATASET & TRAINING CONFIGURATION ---\n",
            "  - AI Target Device:                  CUDA\n",
            "  - GNN Training Molecules:            6870\n",
            "  - GNN Validation Molecules:          1408\n",
            "  - GNN Test Molecules:                1461\n",
            "  - GNN Training Epochs:               50\n",
            "  --------------------------------------------------\n",
            "  - RNN Training Molecules:            9739\n",
            "  - RNN Training Epochs:               30\n",
            "\n",
            "--- 2. PREDICTIVE GNN MODEL VALIDATION ---\n",
            "The GNN's performance was rigorously validated on the held-out, unseen Test Set.\n",
            "The Mean Absolute Error (MAE) measures the average error of our predictions.\n",
            "\n",
            "  **Final GNN Performance on Test Set:**\n",
            "    - MAE for pchembl_value       : 0.6167\n",
            "    - MAE for logp                : 0.2194\n",
            "    - MAE for molecular_weight    : 14.2096\n",
            "\n",
            "--- 3. GENERATIVE RNN MODEL VALIDATION ---\n",
            "The RNN's performance is validated by the quality and novelty of the molecules it creates.\n",
            "\n",
            "  **Generation Statistics:**\n",
            "    - Total Valid Molecules Generated:   198\n",
            "    - Novel Molecules Reported:          198 (Note: No external novelty check performed)\n",
            "\n",
            "  **Conclusion:** The RNN has successfully generated valid molecular structures.\n",
            "  Further analysis (e.g., external database search for novelty, in vitro testing)\n",
            "  is required to confirm true novelty and potential as drug candidates.\n",
            "\n",
            "================================================================================\n",
            "                              END OF REPORT\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "#         GNN Performance Spotlight (Predicted vs. Actual)\n",
        "# =============================================================================\n",
        "#\n",
        "# Objective:\n",
        "# To provide a clear, intuitive proof of the GNN's accuracy, this script\n",
        "# takes a random sample of molecules from the unseen test set and displays\n",
        "# their predicted properties side-by-side with the true, known values\n",
        "# from the dataset.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "import torch\n",
        "\n",
        "# This cell assumes the main script has run and these variables are in memory:\n",
        "# - test_data: The held-out test set of graph objects.\n",
        "# - gnn_model: The trained GNN model.\n",
        "# - scalers: The dictionary of fitted StandardScaler objects.\n",
        "# - PROPERTIES_TO_PREDICT: List of property names.\n",
        "# - DEVICE: The active torch device ('cuda' or 'cpu').\n",
        "# - DataLoader: PyG DataLoader\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"              GNN Performance Spotlight: Predicted vs. Actual Values\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'test_data' not in locals() or not test_data:\n",
        "    print(\"\\n'test_data' not found. Please ensure the main pipeline has been run successfully.\")\n",
        "elif 'gnn_model' not in locals():\n",
        "    print(\"\\n'gnn_model' not found. Please ensure the GNN model has been trained.\")\n",
        "elif 'scalers' not in locals():\n",
        "     print(\"\\n'scalers' not found. Please ensure the scalers were fitted.\")\n",
        "else:\n",
        "    # --- 1. Take a random sample from the test set ---\n",
        "    sample_size = min(15, len(test_data))\n",
        "    sample_indices = np.random.choice(len(test_data), sample_size, replace=False)\n",
        "    sample_data = [test_data[i] for i in sample_indices]\n",
        "\n",
        "    sample_loader = DataLoader(sample_data, batch_size=sample_size)\n",
        "\n",
        "    # --- 2. Predict with the GNN ---\n",
        "    gnn_model.eval()\n",
        "    predictions_scaled = []\n",
        "    actual_scaled = []\n",
        "    with torch.no_grad():\n",
        "        for batch in sample_loader:\n",
        "            batch = batch.to(DEVICE)\n",
        "            out = gnn_model(batch)\n",
        "            predictions_scaled.append(out.cpu().numpy())\n",
        "            # Reshape batch.y to (batch_size, N_PROPERTIES) before appending\n",
        "            actual_scaled.append(batch.y.cpu().numpy().reshape(-1, len(PROPERTIES_TO_PREDICT)))\n",
        "\n",
        "    predictions_scaled = np.vstack(predictions_scaled)\n",
        "    actual_scaled = np.vstack(actual_scaled)\n",
        "\n",
        "\n",
        "    # --- 3. Un-scale predictions and actual values and build the comparison table ---\n",
        "    comparison_results = []\n",
        "    headers = [\"SMILES\"]\n",
        "    for prop in PROPERTIES_TO_PREDICT:\n",
        "        headers.append(f\"Pred. {prop}\")\n",
        "        headers.append(f\"Actual {prop}\")\n",
        "        headers.append(f\"Abs Error ({prop})\")\n",
        "\n",
        "    for i in range(sample_size):\n",
        "        row_data = [sample_data[i].smiles]\n",
        "        for j, prop in enumerate(PROPERTIES_TO_PREDICT):\n",
        "            predicted_real = scalers[prop].inverse_transform(predictions_scaled[i, j].reshape(1, -1))[0,0]\n",
        "            actual_real = scalers[prop].inverse_transform(actual_scaled[i, j].reshape(1, -1))[0,0]\n",
        "            error = abs(predicted_real - actual_real)\n",
        "            row_data.extend([f\"{predicted_real:.4f}\", f\"{actual_real:.4f}\", f\"{error:.4f}\"])\n",
        "        comparison_results.append(row_data)\n",
        "\n",
        "\n",
        "    df_comparison = pd.DataFrame(comparison_results, columns=headers)\n",
        "\n",
        "    # --- 4. Display the final report ---\n",
        "    print(f\"\\n--- Comparison Table for {sample_size} Random Molecules from the Unseen Test Set ---\")\n",
        "\n",
        "    # Use display(HTML(...)) for clean notebook formatting\n",
        "    display(HTML(df_comparison.to_html(index=False, justify='left')))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "Nx_JoytKWN8b",
        "outputId": "696d53b0-ab9a-4618-d9e6-2a5c47d06d3f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "              GNN Performance Spotlight: Predicted vs. Actual Values\n",
            "================================================================================\n",
            "\n",
            "--- Comparison Table for 15 Random Molecules from the Unseen Test Set ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>SMILES</th>\n",
              "      <th>Pred. pchembl_value</th>\n",
              "      <th>Actual pchembl_value</th>\n",
              "      <th>Abs Error (pchembl_value)</th>\n",
              "      <th>Pred. logp</th>\n",
              "      <th>Actual logp</th>\n",
              "      <th>Abs Error (logp)</th>\n",
              "      <th>Pred. molecular_weight</th>\n",
              "      <th>Actual molecular_weight</th>\n",
              "      <th>Abs Error (molecular_weight)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>CCCCCCCCCCNC(=O)COc1cc(O)c2c(=O)cc(-c3ccccc3)oc2c1</td>\n",
              "      <td>5.5812</td>\n",
              "      <td>5.6700</td>\n",
              "      <td>0.0889</td>\n",
              "      <td>5.7954</td>\n",
              "      <td>5.8013</td>\n",
              "      <td>0.0059</td>\n",
              "      <td>446.1235</td>\n",
              "      <td>451.5630</td>\n",
              "      <td>5.4395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>C=CC(=O)N1CC[C@H](n2cc(-c3ccncc3)c(-c3cccc(/C=C/c4ncc(C5CC5)o4)c3)n2)C1</td>\n",
              "      <td>5.3539</td>\n",
              "      <td>8.2200</td>\n",
              "      <td>2.8661</td>\n",
              "      <td>5.2670</td>\n",
              "      <td>5.6073</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>491.4383</td>\n",
              "      <td>477.5680</td>\n",
              "      <td>13.8703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>CC(C)(O)Cn1/c(=N/C(=O)c2ccnc(-c3cccnc3)c2)[nH]c2cc(CC(=O)N3CCCCC3)ccc21</td>\n",
              "      <td>7.4393</td>\n",
              "      <td>6.7500</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>3.6958</td>\n",
              "      <td>3.4934</td>\n",
              "      <td>0.2024</td>\n",
              "      <td>525.3917</td>\n",
              "      <td>512.6140</td>\n",
              "      <td>12.7777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>O=C(/C=C/CN1CCCCC1)N1CCOc2c1ccc1ncnc(Nc3ccc(Oc4ccn5ncnc5c4)c(Cl)c3)c21</td>\n",
              "      <td>6.4300</td>\n",
              "      <td>6.5600</td>\n",
              "      <td>0.1300</td>\n",
              "      <td>5.3964</td>\n",
              "      <td>5.6293</td>\n",
              "      <td>0.2329</td>\n",
              "      <td>558.7992</td>\n",
              "      <td>597.0790</td>\n",
              "      <td>38.2798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Cc1ccc(C2=NN(C3=NC(=O)CS3)C(c3ccccc3)C2)cc1</td>\n",
              "      <td>6.0426</td>\n",
              "      <td>5.9700</td>\n",
              "      <td>0.0726</td>\n",
              "      <td>3.5980</td>\n",
              "      <td>3.7755</td>\n",
              "      <td>0.1776</td>\n",
              "      <td>326.6270</td>\n",
              "      <td>335.4320</td>\n",
              "      <td>8.8050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Oc1c(I)cc(I)c2cccnc12</td>\n",
              "      <td>7.5814</td>\n",
              "      <td>5.7200</td>\n",
              "      <td>1.8614</td>\n",
              "      <td>2.2287</td>\n",
              "      <td>3.1496</td>\n",
              "      <td>0.9209</td>\n",
              "      <td>387.6527</td>\n",
              "      <td>396.9530</td>\n",
              "      <td>9.3003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>CCCCOc1ncnc2[nH]c(-c3ccc(N4CCN(C)CC4)cc3)c(-c3cccc(NC(=O)CC)c3)c12</td>\n",
              "      <td>7.3147</td>\n",
              "      <td>8.0300</td>\n",
              "      <td>0.7153</td>\n",
              "      <td>5.5099</td>\n",
              "      <td>5.5711</td>\n",
              "      <td>0.0612</td>\n",
              "      <td>521.1715</td>\n",
              "      <td>512.6580</td>\n",
              "      <td>8.5135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>COc1cc2c(Oc3ccc(NC(=O)c4c(C)n(C)n(-c5ccccc5)c4=O)cc3F)ccnc2cc1OCCCN1CCN(C)CC1</td>\n",
              "      <td>6.7867</td>\n",
              "      <td>5.1200</td>\n",
              "      <td>1.6667</td>\n",
              "      <td>5.0627</td>\n",
              "      <td>5.2412</td>\n",
              "      <td>0.1785</td>\n",
              "      <td>657.3498</td>\n",
              "      <td>654.7430</td>\n",
              "      <td>2.6068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>CCN1CCC(N2C=C(C(Nc3cc(Cl)c4ncc(C#N)c(Nc5ccc(F)c(Cl)c5)c4c3)c3cncnc3)NN2)CC1</td>\n",
              "      <td>8.5598</td>\n",
              "      <td>8.3000</td>\n",
              "      <td>0.2598</td>\n",
              "      <td>5.9028</td>\n",
              "      <td>5.8897</td>\n",
              "      <td>0.0132</td>\n",
              "      <td>593.2360</td>\n",
              "      <td>619.5360</td>\n",
              "      <td>26.3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>CCCN(CC#CC(=O)Nc1ccc2ncc(C#N)c(Nc3cccc(Br)c3)c2c1)CCC</td>\n",
              "      <td>6.1682</td>\n",
              "      <td>6.8900</td>\n",
              "      <td>0.7218</td>\n",
              "      <td>5.2052</td>\n",
              "      <td>5.6765</td>\n",
              "      <td>0.4713</td>\n",
              "      <td>472.6997</td>\n",
              "      <td>504.4320</td>\n",
              "      <td>31.7323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>COc1cc(N2CCN(C)CC2)ccc1Nc1ncc(F)c(-c2cc(F)c3nc(C)c(C(C)C)n3c2)n1</td>\n",
              "      <td>6.6642</td>\n",
              "      <td>7.1200</td>\n",
              "      <td>0.4558</td>\n",
              "      <td>4.8093</td>\n",
              "      <td>5.0053</td>\n",
              "      <td>0.1960</td>\n",
              "      <td>517.2208</td>\n",
              "      <td>507.5890</td>\n",
              "      <td>9.6318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>CC(COC(=O)c1cc(NCc2cc(O)ccc2O)ccc1O)Cc1ccccc1</td>\n",
              "      <td>5.9677</td>\n",
              "      <td>6.4400</td>\n",
              "      <td>0.4723</td>\n",
              "      <td>4.2946</td>\n",
              "      <td>4.4511</td>\n",
              "      <td>0.1565</td>\n",
              "      <td>406.4628</td>\n",
              "      <td>407.4660</td>\n",
              "      <td>1.0032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Cc1ccc([C@H](Nc2cc(Cl)c3ncc(C#N)c(Nc4ccc(F)c(Cl)c4)c3c2)C2=CN(COC(=O)C(C)(C)C)NN2)cn1</td>\n",
              "      <td>7.8887</td>\n",
              "      <td>7.2900</td>\n",
              "      <td>0.5987</td>\n",
              "      <td>6.6460</td>\n",
              "      <td>6.8656</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>595.4189</td>\n",
              "      <td>635.5310</td>\n",
              "      <td>40.1121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Clc1cccc(Nc2[nH]cnc3nnc(-c4ccccc4)c2-3)c1</td>\n",
              "      <td>6.9061</td>\n",
              "      <td>7.7200</td>\n",
              "      <td>0.8139</td>\n",
              "      <td>4.2215</td>\n",
              "      <td>4.3685</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>323.1540</td>\n",
              "      <td>321.7710</td>\n",
              "      <td>1.3830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>C[C@@H](Nc1ncnc2[nH]c(-c3cccc(C(N)=O)c3)cc12)c1ccccc1</td>\n",
              "      <td>8.9130</td>\n",
              "      <td>8.8500</td>\n",
              "      <td>0.0630</td>\n",
              "      <td>3.9554</td>\n",
              "      <td>3.8969</td>\n",
              "      <td>0.0585</td>\n",
              "      <td>365.8596</td>\n",
              "      <td>357.4170</td>\n",
              "      <td>8.4426</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}